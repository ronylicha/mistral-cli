from mistral_cli.cli import Context
from .file_reader import FileAnalyzer
import os
import json
from pathlib import Path
from typing import List, Dict, Any
import fnmatch

def execute(context: Context) -> Context:
    """Traitement par lots de fichiers avec analyse Mistral."""
    
    # R√©cup√©rer les param√®tres
    directory = context.data.get("directory", ".")
    patterns = context.data.get("patterns", ["*.py", "*.js", "*.ts", "*.java", "*.go"])
    analysis_type = context.data.get("analysis_type", "general")
    recursive = context.data.get("recursive", True)
    apply_improvements = context.data.get("apply_improvements", False)
    max_file_size = context.data.get("max_file_size", 100000)  # 100KB max par d√©faut
    
    api_key = context.data.get("api_key")
    if not api_key:
        context.data["output"] = "Erreur: Cl√© API Mistral manquante."
        return context
    
    if not os.path.exists(directory):
        context.data["output"] = f"Erreur: R√©pertoire '{directory}' inexistant."
        return context
    
    try:
        analyzer = FileAnalyzer(api_key)
        results = []
        processed_files = 0
        errors = []
        
        # Trouver tous les fichiers correspondants aux patterns
        files_to_process = []
        
        if recursive:
            for root, dirs, files in os.walk(directory):
                # Ignorer les r√©pertoires cach√©s et de build courants
                dirs[:] = [d for d in dirs if not d.startswith('.') and d not in ['node_modules', 'build', 'dist', '__pycache__', 'target']]
                
                for file in files:
                    file_path = os.path.join(root, file)
                    if any(fnmatch.fnmatch(file, pattern) for pattern in patterns):
                        if os.path.getsize(file_path) <= max_file_size:
                            files_to_process.append(file_path)
                        else:
                            errors.append(f"Fichier ignor√© (trop volumineux): {file_path}")
        else:
            for file in os.listdir(directory):
                file_path = os.path.join(directory, file)
                if os.path.isfile(file_path) and any(fnmatch.fnmatch(file, pattern) for pattern in patterns):
                    if os.path.getsize(file_path) <= max_file_size:
                        files_to_process.append(file_path)
                    else:
                        errors.append(f"Fichier ignor√© (trop volumineux): {file_path}")
        
        # Traiter chaque fichier
        for file_path in files_to_process:
            try:
                print(f"Traitement de: {file_path}")
                
                # Lire le contenu
                content = analyzer.read_file_content(file_path)
                if content.startswith("Erreur"):
                    errors.append(f"{file_path}: {content}")
                    continue
                
                # Analyser
                analysis = analyzer.analyze_with_mistral(content, analysis_type)
                suggestions = analyzer.generate_improvements(content, analysis)
                
                # Appliquer les am√©liorations si demand√©
                applied = False
                if apply_improvements:
                    applied = analyzer.apply_suggestions(file_path, content, suggestions)
                
                file_result = {
                    "file_path": file_path,
                    "file_size": len(content),
                    "analysis": analysis,
                    "suggestions": suggestions,
                    "improvements_applied": applied
                }
                
                results.append(file_result)
                processed_files += 1
                
            except Exception as e:
                errors.append(f"{file_path}: Erreur - {str(e)}")
        
        # G√©n√©rer un rapport de synth√®se
        summary = generate_batch_summary(results, analysis_type)
        
        # Pr√©parer la sortie finale
        output = {
            "summary": summary,
            "total_files_found": len(files_to_process),
            "files_processed": processed_files,
            "files_with_errors": len(errors),
            "analysis_type": analysis_type,
            "directory": directory,
            "patterns": patterns,
            "errors": errors[:10],  # Limiter les erreurs affich√©es
            "detailed_results": results[:5] if len(results) <= 5 else results[:5] + [{"note": f"... et {len(results)-5} autres fichiers"}]
        }
        
        context.data["output"] = json.dumps(output, indent=2, ensure_ascii=False)
        
    except Exception as e:
        context.data["output"] = f"Erreur lors du traitement par lots: {str(e)}"
    
    return context

def generate_batch_summary(results: List[Dict[str, Any]], analysis_type: str) -> str:
    """G√©n√®re un r√©sum√© des r√©sultats de l'analyse par lots."""
    
    if not results:
        return "Aucun fichier trait√© avec succ√®s."
    
    total_files = len(results)
    files_with_improvements = sum(1 for r in results if r.get("improvements_applied", False))
    
    # Compter les types de probl√®mes les plus fr√©quents (analyse basique)
    common_issues = {}
    
    for result in results:
        analysis = result.get("analysis", "").lower()
        # Rechercher des mots-cl√©s de probl√®mes courants
        if "security" in analysis or "s√©curit√©" in analysis:
            common_issues["S√©curit√©"] = common_issues.get("S√©curit√©", 0) + 1
        if "performance" in analysis:
            common_issues["Performance"] = common_issues.get("Performance", 0) + 1
        if "bug" in analysis or "erreur" in analysis:
            common_issues["Bugs potentiels"] = common_issues.get("Bugs potentiels", 0) + 1
        if "documentation" in analysis:
            common_issues["Documentation"] = common_issues.get("Documentation", 0) + 1
        if "style" in analysis or "convention" in analysis:
            common_issues["Style/Conventions"] = common_issues.get("Style/Conventions", 0) + 1
    
    summary = f"""
=== R√âSUM√â DE L'ANALYSE PAR LOTS ===

üìä Statistiques g√©n√©rales:
‚Ä¢ Fichiers analys√©s: {total_files}
‚Ä¢ Fichiers am√©lior√©s: {files_with_improvements}
‚Ä¢ Type d'analyse: {analysis_type}

üîç Probl√®mes les plus fr√©quents:"""
    
    if common_issues:
        for issue, count in sorted(common_issues.items(), key=lambda x: x[1], reverse=True):
            percentage = (count / total_files) * 100
            summary += f"\n‚Ä¢ {issue}: {count} fichiers ({percentage:.1f}%)"
    else:
        summary += "\n‚Ä¢ Aucun probl√®me majeur d√©tect√©"
    
    summary += f"""

üí° Recommandations:
‚Ä¢ Examinez les fichiers avec des probl√®mes de s√©curit√© en priorit√©
‚Ä¢ Consid√©rez l'am√©lioration de la documentation manquante
‚Ä¢ Appliquez les suggestions de style pour une meilleure lisibilit√©
"""
    
    return summary